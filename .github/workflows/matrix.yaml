name: Process URLs

on:
  push:
    branches: ["*"]
  schedule:
    - cron: '0 0 * * *'  # Runs at 00:00 UTC every day
  workflow_dispatch:      # Allows manual triggering
    inputs:
      matrixCount:
        description: 'Number of URLs to process in parallel'
        required: true
        default: '5'

concurrency: 
  group: "scans"
  cancel-in-progress: false

env:
  MATRIX_MAX_COUNT: "${{ inputs.matrixCount || 3 }}"

jobs:
  prepare-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          
      - name: Process URL list
        id: set-matrix
        run: |
          # Create a Python script to process URLs
          cat << 'EOF' > process_urls.py
          import os
          import base64
          import json
          import sys
          import subprocess
          from datetime import datetime
          
          def get_b64_path(url):
              return os.path.join('./out', base64.b64encode(url.encode()).decode())
          
          def get_git_last_modified(path):
              try:
                  # Get the last commit date for the file
                  result = subprocess.run(
                      ['git', 'log', '-1', '--format=%at', '--', path],
                      capture_output=True,
                      text=True
                  )
                  print(result)
                  if result.stdout.strip():
                      return float(result.stdout.strip())
                  return float('-inf')  # File doesn't exist in git history
              except Exception:
                  print("error")
                  return float('-inf')  # Error running git command
          
          
          # Read URLs from file
          with open('urls.txt', 'r') as f:
              urls = [line.strip() for line in f if line.strip()]
          
          # Sort URLs based on existence and modification time
          sorted_urls = sorted(
              urls,
              key=lambda url: (
                  os.path.exists(get_b64_path(url)),
                  get_git_last_modified(get_b64_path(url))
              )
          )
          
          # Take only the first N URLs (from input)
          matrix_count = int(sys.argv[1])
          matrix_urls = sorted_urls[:matrix_count]
          
          # Output the matrix JSON to GITHUB_OUTPUT
          matrix_json = json.dumps({'url': matrix_urls})
          with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
              fh.write(f"matrix={matrix_json}")
          EOF
          
          python process_urls.py ${{ env.MATRIX_MAX_COUNT }}

  process-urls:
    needs: prepare-matrix
    runs-on: ubuntu-latest
    strategy:
      matrix:
        url: ${{ fromJson(needs.prepare-matrix.outputs.matrix).url }}
      # Prevent all jobs from failing if one fails
      fail-fast: false
      
    steps:
      - name: Process URL
        run: |
          echo "Processing URL: ${{ matrix.url }}"
